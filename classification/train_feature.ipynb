{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import *\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "import os\n",
    "np.random.seed(2018)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read featureï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filelist = [\"feature_Xception.h5\", \"feature_InceptionV3.h5\", \"feature_InceptionResNetV2.h5\"]\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in h5_filelist:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5632)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model adjustment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = input_tensor\n",
    "x = BatchNormalization(axis=1, name='bn_1')(x)\n",
    "x = Dropout(0.8, name='dropout_1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc_1')(x)\n",
    "x = BatchNormalization(axis=1, name='bn_2')(x)\n",
    "x = Dropout(0.9, name='dropout_2')(x)\n",
    "\n",
    "x = Dense(1, activation='sigmoid', name='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x, dense_num: int, block_index: int):\n",
    "    block_name = 'top_block_' + str(block_index) + '_'\n",
    "    res = x\n",
    "    x = Dense(dense_num, activation=None, name=block_name + 'fc_1')(x)\n",
    "    x = BatchNormalization(axis=1, name=block_name + 'bn_1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(dense_num, activation=None, name=block_name + 'fc_2')(x)\n",
    "    x = BatchNormalization(axis=1, name=block_name + 'bn_2')(x)\n",
    "    x = add([x, res])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = input_tensor\n",
    "x = BatchNormalization(axis=1, name='top_bn_1')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(1024, activation=None, name='top_fc_1')(x)\n",
    "x = BatchNormalization(axis=1, name='top_bn_2')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = identity_block(x, 1024, block_index=1)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(1, activation='sigmoid', name='top_sigmoid')(x)\n",
    "\n",
    "model = Model(input_tensor, x)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 0.0306 - acc: 0.9918 - val_loss: 0.0263 - val_acc: 0.9928\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.0272 - acc: 0.9925 - val_loss: 0.0250 - val_acc: 0.9936\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.0251 - acc: 0.9929 - val_loss: 0.0254 - val_acc: 0.9936\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.0236 - acc: 0.9938 - val_loss: 0.0250 - val_acc: 0.9934\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.0262 - acc: 0.9928 - val_loss: 0.0261 - val_acc: 0.9930\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 2s 106us/step - loss: 0.0266 - acc: 0.9925 - val_loss: 0.0249 - val_acc: 0.9928\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0250 - val_acc: 0.9928\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.0198 - acc: 0.9932 - val_loss: 0.0241 - val_acc: 0.9932\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.0179 - acc: 0.9945 - val_loss: 0.0234 - val_acc: 0.9936\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0230 - val_acc: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e501d6898>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train in total training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('model_weights.h5'):\n",
    "    os.remove('model_weights.h5')\n",
    "\n",
    "model.save_weights('model_weights.h5')\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 5s 217us/step - loss: 0.0720 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 0.0336 - acc: 0.9911\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 0.0269 - acc: 0.9910\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 0.0253 - acc: 0.9920\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.0227 - acc: 0.9924\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.0206 - acc: 0.9932\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.0180 - acc: 0.9940\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 0.0188 - acc: 0.9932\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 0.0155 - acc: 0.9943\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 0.0154 - acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e501c66d8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=10, validation_split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 3s 222us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sampleSubmission.csv\")\n",
    "\n",
    "image_size = (224, 224)\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(\"test\", image_size, shuffle=False, \n",
    "                                         batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.loc[index-1, ['label']] = y_pred[i]\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
