{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from utils import box_iou, letterbox_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = '../oxford_data/annotations/xmls'\n",
    "image_path = '../oxford_data/images/'\n",
    "file_list = os.listdir(xml_path)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_name = ['cat', 'dog']\n",
    "num_anchors = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read anchors\n",
    "with open('yolo_anchors.txt') as f:\n",
    "    anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    anchors = np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sample data when testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['miniature_pinscher_185.xml', 'Bengal_120.xml', 'american_bulldog_112.xml', 'havanese_158.xml', 'pug_175.xml', 'Russian_Blue_158.xml', 'Maine_Coon_203.xml', 'english_cocker_spaniel_128.xml', 'beagle_189.xml', 'japanese_chin_181.xml']\n"
     ]
    }
   ],
   "source": [
    "random.seed(2018)\n",
    "choose_file_index = random.sample([i for i in range(len(file_list))], 1000)\n",
    "file_list = [file_list[i] for i in choose_file_index]\n",
    "print(len(file_list))\n",
    "print(file_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_list, image_path):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        file_list: xml file names.\n",
    "        image_path: image file path.\n",
    "    \"\"\"\n",
    "    image_wh = []\n",
    "    for i, file in enumerate(tqdm(file_list)):\n",
    "        image = Image.open(image_path + file[:-4] + '.jpg')\n",
    "        image_wh.append(image.size)\n",
    "        image = letterbox_image(image, (416, 416))\n",
    "        image = np.array(image, dtype='uint8')\n",
    "        image = np.expand_dims(image, 0)\n",
    "        if i == 0:\n",
    "            X = image\n",
    "        else:\n",
    "            X = np.concatenate([X, image], axis=0)\n",
    "        \n",
    "    return X, image_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:11<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 416, 416, 3)\n"
     ]
    }
   ],
   "source": [
    "X, image_wh = read_image(file_list, image_path)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_boxes(file_list, xml_path):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        file_list: xml file names.\n",
    "        xml_path: xml file path.\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    for file in tqdm(file_list):\n",
    "        tree =  ET.ElementTree(file=xml_path + os.sep + file)\n",
    "        xmin = []\n",
    "        xmax = []\n",
    "        ymin = []\n",
    "        ymax = []\n",
    "        for elem in tree.iterfind('object/bndbox/xmin'):\n",
    "            xmin.append(int(elem.text))\n",
    "\n",
    "        for elem in tree.iterfind('object/bndbox/xmax'):\n",
    "            xmax.append(int(elem.text))\n",
    "\n",
    "        for elem in tree.iterfind('object/bndbox/ymin'):\n",
    "            ymin.append(int(elem.text))\n",
    "\n",
    "        for elem in tree.iterfind('object/bndbox/ymax'):\n",
    "            ymax.append(int(elem.text))\n",
    "\n",
    "        xmin = np.array(xmin).reshape(-1, 1)\n",
    "        xmax = np.array(xmax).reshape(-1, 1)\n",
    "        ymin = np.array(ymin).reshape(-1, 1)\n",
    "        ymax = np.array(ymax).reshape(-1, 1)\n",
    "        box = np.concatenate([xmin, ymin, xmax, ymax], axis=-1) - 1\n",
    "        boxes.append(box)\n",
    "        \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 342.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "boxes = read_boxes(file_list, xml_path)\n",
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(boxes)):\n",
    "    for j in range(boxes[i].shape[0]):\n",
    "        xmin = boxes[i][j, 0]\n",
    "        ymin = boxes[i][j, 1]\n",
    "        xmax = boxes[i][j, 2]\n",
    "        ymax = boxes[i][j, 3]\n",
    "        if xmin < 0:\n",
    "            print(file_list[i], ' xmin=', xmin)\n",
    "        if xmax >= image_wh[i][0]:\n",
    "            print(file_list[i], ' xmax=', xmax)\n",
    "        if ymin < 0:\n",
    "            print(file_list[i], ' ymin=', ymin)\n",
    "        if ymax >= image_wh[i][1]:\n",
    "            print(file_list[i], ' ymax=', ymax)\n",
    "            \n",
    "        if xmax-xmin <= 0:\n",
    "            print(file_list[i], ' xmax=', xmax, ' xmin=', xmin)\n",
    "        if ymax-ymin <= 0:\n",
    "            print(file_list[i], ' ymax=', ymax, ' ymin=', ymin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read y classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "y_classes = np.zeros(len(file_list), dtype='int32')\n",
    "for i, file in enumerate(file_list):\n",
    "    if file[0].islower():\n",
    "        y_classes[i] = 1\n",
    "        \n",
    "print(y_classes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer boxes to y format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes_to_y(true_boxes, box_class, anchors, num_classes, image_wh):\n",
    "    \"\"\"\n",
    "    transfer true boxes to yolo y format.\n",
    "    Arguments:\n",
    "        true_boxes: bbox absolute value in image_wh of one image, value as (xmin, ymin, xmax, ymax), shape(?, 4).\n",
    "        box_class: 0/1 - cat/dog.\n",
    "        anchors: anchor boxe size array, shape(num_anchors, 2).\n",
    "        num_classes: total class num.\n",
    "        image_wh: true input image size of (w, h).\n",
    "        \n",
    "    Returns:\n",
    "        y_true: xywh fomat, shape(box_num, 4).\n",
    "    \"\"\"\n",
    "    # transfer xy to range(0, 416).\n",
    "    xymin, xymax = true_boxes[:, 0:2], true_boxes[:, 2:4]\n",
    "    \n",
    "    input_size = np.array([416, 416])\n",
    "    zoom_scale = np.min(input_size/image_wh)\n",
    "    image_wh = np.array(image_wh)\n",
    "    nopadding_wh = np.round(image_wh * zoom_scale)  # w,h==416 or one of w,h < 416.\n",
    "    padding_offset = (input_size - nopadding_wh)//2  # padding to 416.\n",
    "    \n",
    "    xymin = xymin * zoom_scale + padding_offset\n",
    "    xymax = xymax * zoom_scale + padding_offset\n",
    "    \n",
    "    # calculate box center xy and wh, range(0, 416).\n",
    "    boxes_wh = xymax - xymin\n",
    "    boxes_xy = xymin + boxes_wh//2\n",
    "    \n",
    "    # normalize to range(0, 1)\n",
    "    boxes_xy /= input_size\n",
    "    \n",
    "    # grid shape\n",
    "    grid_wh = [input_size//32, input_size//16, input_size//8]  # [[13, 13], [26, 26], [52, 52]]\n",
    "    grid_boxes_xy = [boxes_xy * grid_wh[i] for i in range(3)]  # to grid scale, range(0, grid_wh).\n",
    "    grid_index = [np.floor(grid_boxes_xy[i]) for i in range(3)]\n",
    "    # boxes_xy = [(boxes_xy[i] - grid_index[i]) for i in range(3)]  # size respect to one grid, range(0, 1).\n",
    "    \n",
    "    # true size of xy min max cordinates relative to grid left top corner.\n",
    "    anchor_xymax = anchors/2\n",
    "    anchor_xymin = -anchor_xymax\n",
    "    box_xymax = boxes_wh/2\n",
    "    box_xymin = -box_xymax\n",
    "    \n",
    "    # create y_true.\n",
    "    y_true = [np.zeros((grid_wh[i][1], grid_wh[i][0], 3, 5+num_classes), dtype='float32') for i in range(3)]\n",
    "    \n",
    "    # iterate on each box\n",
    "    num_boxes = true_boxes.shape[0]\n",
    "    for box_index in range(num_boxes):\n",
    "        # calculate iou.\n",
    "        box1 = np.concatenate([box_xymin[box_index], box_xymax[box_index]]).reshape(1, -1)\n",
    "        box2 = np.concatenate([anchor_xymin, anchor_xymax], axis=-1)\n",
    "        iou = box_iou(box1, box2)\n",
    "        \n",
    "        # select the best anchor\n",
    "        anchor_index = np.argmax(iou)\n",
    "        layer_index = 2 - anchor_index//3\n",
    "        layer_anchor_index = anchor_index % 3\n",
    "        \n",
    "        box_xy = boxes_xy[box_index]  # shape(2,)\n",
    "        # box_wh = boxes_wh[box_index]/anchors[anchor_index]  # shape(2,)\n",
    "        box_wh = boxes_wh[box_index]/input_size  # shape(2,)， range(0, 1)\n",
    "        \n",
    "        #  fill in y_true.\n",
    "        w = grid_index[layer_index][box_index, 0].astype('int32')\n",
    "        h = grid_index[layer_index][box_index, 1].astype('int32')\n",
    "        y_true[layer_index][h, w, layer_anchor_index, :2] = box_xy\n",
    "        y_true[layer_index][h, w, layer_anchor_index, 2:4] = box_wh\n",
    "        y_true[layer_index][h, w, layer_anchor_index, 4:5] = 1\n",
    "        y_true[layer_index][h, w, layer_anchor_index, 5+box_class] = 1\n",
    "        \n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:11<00:00, 14.07it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "for i in tqdm(range(len(boxes))):\n",
    "    _y_true = boxes_to_y(boxes[i], y_classes[i], anchors, num_classes, image_wh[i])\n",
    "    _y_true = [np.expand_dims(_y_true[j], axis=0) for j in range(3)]\n",
    "    if i == 0:\n",
    "        y_true = _y_true\n",
    "    else:\n",
    "        y_true = [np.concatenate([y_true[j], _y_true[j]], axis=0) for j in range(3)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 13, 13, 3, 7) (1000, 26, 26, 3, 7) (1000, 52, 52, 3, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y_true[0].shape, y_true[1].shape, y_true[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape, dtype=None):\n",
    "    return K.random_normal(shape, stddev=1e-4, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('yolo.h5')\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "y = [model.layers[-6].output, model.layers[-5].output, model.layers[-4].output]\n",
    "for i in range(3):\n",
    "    y[i] = Conv2D(num_anchors*(num_classes+5), (1, 1),\n",
    "                  padding='same',\n",
    "                  kernel_initializer=my_init,\n",
    "                  kernel_regularizer=l2(5e-4),\n",
    "                  name='conv2d_%d'%(59+i*8))(y[i])\n",
    "    \n",
    "model = Model(model.input, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 416, 416, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 416, 416, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 417, 417, 32) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 208, 208, 64) 18432       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 208, 208, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 208, 208, 32) 2048        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 208, 208, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 208, 208, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 208, 208, 64) 18432       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 208, 208, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 208, 208, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 208, 208, 64) 0           leaky_re_lu_2[0][0]              \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 209, 209, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 104, 104, 128 73728       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 104, 104, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 104, 104, 64) 8192        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 104, 104, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 104, 104, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 104, 104, 128 73728       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 104, 104, 128 512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 104, 104, 128 0           leaky_re_lu_5[0][0]              \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 104, 104, 64) 8192        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 104, 104, 64) 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 104, 104, 64) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 104, 104, 128 73728       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 104, 104, 128 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 104, 104, 128 0           add_2[0][0]                      \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 105, 105, 128 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 52, 52, 256)  294912      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 52, 52, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 52, 52, 128)  32768       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_11 (BatchNo (None, 52, 52, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 52, 52, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 52, 52, 256)  0           leaky_re_lu_10[0][0]             \n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 52, 52, 128)  32768       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 52, 52, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 52, 52, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 52, 52, 256)  0           add_4[0][0]                      \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 52, 52, 128)  32768       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 52, 52, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 52, 52, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 52, 52, 256)  0           add_5[0][0]                      \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 52, 52, 128)  32768       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 52, 52, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 52, 52, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 52, 52, 256)  0           add_6[0][0]                      \n",
      "                                                                 leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 52, 52, 128)  32768       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 52, 52, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 52, 52, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 52, 52, 256)  0           add_7[0][0]                      \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 52, 52, 128)  32768       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 52, 52, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 52, 52, 256)  1024        conv2d_22[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 52, 52, 256)  0           add_8[0][0]                      \n",
      "                                                                 leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 52, 52, 128)  32768       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 52, 52, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 52, 52, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 52, 52, 256)  0           add_9[0][0]                      \n",
      "                                                                 leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 52, 52, 128)  32768       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 52, 52, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 52, 52, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 52, 52, 256)  0           add_10[0][0]                     \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 53, 53, 256)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 26, 26, 512)  1179648     zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 26, 26, 512)  2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 26, 26, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 26, 26, 512)  2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 26, 26, 512)  0           leaky_re_lu_27[0][0]             \n",
      "                                                                 leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 26, 26, 256)  131072      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 26, 26, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 26, 26, 512)  2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 26, 26, 512)  0           add_12[0][0]                     \n",
      "                                                                 leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 26, 26, 256)  131072      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 26, 26, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_33 (BatchNo (None, 26, 26, 512)  2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 26, 26, 512)  0           add_13[0][0]                     \n",
      "                                                                 leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 26, 26, 256)  131072      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 26, 26, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 26, 26, 512)  2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 26, 26, 512)  0           add_14[0][0]                     \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 26, 26, 256)  131072      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 26, 26, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 26, 26, 512)  2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 26, 26, 512)  0           add_15[0][0]                     \n",
      "                                                                 leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 26, 26, 256)  131072      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 26, 26, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 26, 26, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 26, 26, 512)  0           add_16[0][0]                     \n",
      "                                                                 leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 26, 26, 256)  131072      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 26, 26, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 26, 26, 512)  2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 26, 26, 512)  0           add_17[0][0]                     \n",
      "                                                                 leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 26, 26, 256)  131072      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 26, 26, 256)  1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 26, 26, 512)  2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 26, 26, 512)  0           add_18[0][0]                     \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_padding2d_5 (ZeroPadding2D (None, 27, 27, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 13, 13, 1024) 4718592     zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 13, 13, 1024) 4096        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 13, 13, 512)  2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 13, 13, 1024) 4096        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 13, 13, 1024) 0           leaky_re_lu_44[0][0]             \n",
      "                                                                 leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 13, 13, 512)  524288      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 13, 13, 512)  2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 13, 13, 1024) 4096        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 13, 13, 1024) 0           add_20[0][0]                     \n",
      "                                                                 leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 13, 13, 512)  524288      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 13, 13, 512)  2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 13, 13, 1024) 4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 13, 13, 1024) 0           add_21[0][0]                     \n",
      "                                                                 leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 13, 13, 512)  524288      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 13, 13, 512)  2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 13, 13, 1024) 4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 13, 13, 1024) 0           add_22[0][0]                     \n",
      "                                                                 leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 13, 13, 512)  524288      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 13, 13, 512)  2048        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 13, 13, 1024) 4096        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_55 (BatchNo (None, 13, 13, 512)  2048        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 13, 13, 1024) 4096        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 13, 13, 512)  2048        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 13, 13, 256)  131072      leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 13, 13, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, 13, 13, 256)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 26, 26, 256)  0           leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 26, 26, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 26, 26, 256)  196608      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 26, 26, 256)  1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 26, 26, 512)  2048        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 26, 26, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 26, 26, 512)  2048        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 26, 26, 256)  1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 26, 26, 128)  32768       leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 26, 26, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 26, 26, 128)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 52, 52, 128)  0           leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 52, 52, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 52, 52, 128)  49152       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 52, 52, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 52, 52, 256)  1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 52, 52, 128)  32768       leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_69 (BatchNo (None, 52, 52, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 52, 52, 256)  1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 52, 52, 128)  32768       leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 52, 52, 128)  512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 52, 52, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 52, 52, 256)  294912      leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 13, 13, 1024) 4096        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 26, 26, 512)  2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 52, 52, 256)  1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 52, 52, 256)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 13, 13, 21)   21525       leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 26, 26, 21)   10773       leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 52, 52, 21)   5397        leaky_re_lu_72[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 61,581,727\n",
      "Trainable params: 37,695\n",
      "Non-trainable params: 61,544,032\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(args, anchors, num_classes):\n",
    "    feats = args[:3]\n",
    "    y_true = args[3:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]]\n",
    "    num_anchors = len(anchor_mask)\n",
    "    input_wh = K.constant([416, 416])\n",
    "    batch_size = K.shape(feats[0])[0]\n",
    "    loss = 0\n",
    "    \n",
    "    # iterate along 3 layers.\n",
    "    for i in range(3):\n",
    "        # get anchor tensor\n",
    "        anchors_tensor = K.reshape(K.constant(anchors[anchor_mask[i]]), [1, 1, 1, num_anchors, 2])\n",
    "        \n",
    "        # get grid\n",
    "        grid_hw = K.shape(feats[i])[1:3]\n",
    "        grid_y = K.tile(K.reshape(K.arange(0, stop=grid_hw[0]), [-1, 1, 1, 1]), [1, grid_hw[1], 1, 1])\n",
    "        grid_x = K.tile(K.reshape(K.arange(0, stop=grid_hw[1]), [1, -1, 1, 1]), [grid_hw[0], 1, 1, 1])\n",
    "        grid = K.concatenate([grid_x, grid_y])\n",
    "        grid = K.cast(grid, K.dtype(feats[i]))\n",
    "        \n",
    "        # get prediction values\n",
    "        feature = K.reshape(feats[i], [-1, grid_hw[0], grid_hw[1], num_anchors, num_classes + 5])\n",
    "        box_xy = K.sigmoid(feature[..., :2])\n",
    "        box_wh = K.exp(feature[..., 2:4])\n",
    "        box_confidence = K.sigmoid(feature[..., 4:5])\n",
    "        box_class_probs = K.sigmoid(feature[..., 5:])\n",
    "        box_xy = (box_xy + grid) / K.cast(grid_hw[::-1], K.dtype(feature))\n",
    "        box_wh = box_wh * anchors_tensor / K.cast(input_wh, K.dtype(feature))\n",
    "        \n",
    "        # get true values\n",
    "        ture_xy = y_true[i][..., :2]\n",
    "        true_wh = y_true[i][..., 2:4]\n",
    "        true_confidence = y_true[i][..., 4:5]\n",
    "        true_class_probs = y_true[i][..., 5:]\n",
    "        \n",
    "        # calculate loss\n",
    "        lambda_cord = K.constant(5)\n",
    "        \n",
    "        # shape(batch, grid_h, grid_w, num_anchors, 2)\n",
    "        xy_loss = lambda_cord * K.square(true_confidence * box_xy - ture_xy)\n",
    "        \n",
    "        wh_loss = lambda_cord * K.square(true_confidence * K.sqrt(box_wh) - K.sqrt(true_wh))\n",
    "        \n",
    "        # iou_loss = -true_confidence*K.log(box_confidence) - (1-true_confidence)*K.log(1-box_confidence)\n",
    "        iou_loss = K.square(true_confidence-box_confidence)\n",
    "        iou_loss = true_confidence*iou_loss + 0.5 * (1-true_confidence)*iou_loss\n",
    "        \n",
    "        class_loss = K.square(true_confidence * box_class_probs - true_class_probs)\n",
    "        \n",
    "        loss += K.sum(xy_loss) + K.sum(wh_loss) + K.sum(iou_loss) + K.sum(class_loss)\n",
    "        \n",
    "    return loss/K.cast(batch_size, K.dtype(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = [Input(shape=(13, 13, num_anchors, num_classes+5), name='y_input_1'),\n",
    "            Input(shape=(26, 26, num_anchors, num_classes+5), name='y_input_2'),\n",
    "            Input(shape=(52, 52, num_anchors, num_classes+5), name='y_input_3')]\n",
    "loss_layer = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss', arguments={'anchors': anchors, 'num_classes': num_classes})([*model.output, *y_tensor])\n",
    "\n",
    "train_model = Model([model.input, *y_tensor], loss_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(optimizer=Adam(lr=0.001, clipnorm=1.), loss={'yolo_loss': lambda y_true, y_pred: y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - ETA: 1:24 - loss: 1340.17 - ETA: 45s - loss: 1243.5970 - ETA: 31s - loss: 1147.218 - ETA: 23s - loss: 1055.290 - ETA: 18s - loss: 969.885 - ETA: 15s - loss: 892.35 - ETA: 12s - loss: 822.37 - ETA: 10s - loss: 759.65 - ETA: 7s - loss: 703.5187 - ETA: 6s - loss: 653.416 - ETA: 4s - loss: 608.412 - ETA: 2s - loss: 568.177 - ETA: 1s - loss: 532.238 - ETA: 0s - loss: 499.982 - 23s 26ms/step - loss: 498.0490 - val_loss: 5381353.4800\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 53.540 - ETA: 11s - loss: 48.348 - ETA: 10s - loss: 43.904 - ETA: 9s - loss: 40.439 - ETA: 8s - loss: 37.41 - ETA: 7s - loss: 34.82 - ETA: 6s - loss: 32.62 - ETA: 5s - loss: 30.71 - ETA: 4s - loss: 29.09 - ETA: 3s - loss: 27.66 - ETA: 2s - loss: 26.42 - ETA: 1s - loss: 25.32 - ETA: 1s - loss: 24.34 - ETA: 0s - loss: 23.47 - 15s 17ms/step - loss: 23.4254 - val_loss: 2359256251105.2798\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 11.684 - ETA: 11s - loss: 11.552 - ETA: 10s - loss: 11.452 - ETA: 9s - loss: 11.371 - ETA: 8s - loss: 11.31 - ETA: 7s - loss: 11.25 - ETA: 6s - loss: 11.20 - ETA: 5s - loss: 11.16 - ETA: 4s - loss: 11.12 - ETA: 3s - loss: 11.09 - ETA: 2s - loss: 11.06 - ETA: 1s - loss: 11.04 - ETA: 1s - loss: 11.01 - ETA: 0s - loss: 10.99 - 15s 17ms/step - loss: 10.9933 - val_loss: 2469717502262478336.0000\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 10.717 - ETA: 11s - loss: 10.710 - ETA: 10s - loss: 10.690 - ETA: 9s - loss: 10.682 - ETA: 8s - loss: 10.67 - ETA: 7s - loss: 10.66 - ETA: 6s - loss: 10.65 - ETA: 5s - loss: 10.65 - ETA: 4s - loss: 10.65 - ETA: 3s - loss: 10.64 - ETA: 2s - loss: 10.64 - ETA: 1s - loss: 10.63 - ETA: 1s - loss: 10.63 - ETA: 0s - loss: 10.62 - 15s 17ms/step - loss: 10.6290 - val_loss: 240523.4496\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 10.538 - ETA: 11s - loss: 10.545 - ETA: 10s - loss: 10.546 - ETA: 9s - loss: 10.541 - ETA: 8s - loss: 10.53 - ETA: 7s - loss: 10.53 - ETA: 6s - loss: 10.53 - ETA: 5s - loss: 10.53 - ETA: 4s - loss: 10.53 - ETA: 3s - loss: 10.52 - ETA: 2s - loss: 10.52 - ETA: 1s - loss: 10.52 - ETA: 1s - loss: 10.52 - ETA: 0s - loss: 10.52 - 15s 17ms/step - loss: 10.5222 - val_loss: 186149556.0000\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 10.551 - ETA: 11s - loss: 10.504 - ETA: 10s - loss: 10.492 - ETA: 9s - loss: 10.485 - ETA: 8s - loss: 10.47 - ETA: 7s - loss: 10.46 - ETA: 6s - loss: 10.46 - ETA: 5s - loss: 10.46 - ETA: 4s - loss: 10.46 - ETA: 3s - loss: 10.46 - ETA: 2s - loss: 10.46 - ETA: 1s - loss: 10.47 - ETA: 1s - loss: 10.47 - ETA: 0s - loss: 10.47 - 15s 17ms/step - loss: 10.4730 - val_loss: 201236.2662\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 10.438 - ETA: 11s - loss: 10.459 - ETA: 10s - loss: 10.455 - ETA: 9s - loss: 10.457 - ETA: 8s - loss: 10.45 - ETA: 7s - loss: 10.46 - ETA: 6s - loss: 10.45 - ETA: 5s - loss: 10.45 - ETA: 4s - loss: 10.45 - ETA: 3s - loss: 10.45 - ETA: 2s - loss: 10.45 - ETA: 1s - loss: 10.45 - ETA: 1s - loss: 10.45 - ETA: 0s - loss: 10.44 - 15s 17ms/step - loss: 10.4461 - val_loss: 2197.8083\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 10.442 - ETA: 11s - loss: 10.454 - ETA: 10s - loss: 10.452 - ETA: 9s - loss: 10.443 - ETA: 8s - loss: 10.45 - ETA: 7s - loss: 10.43 - ETA: 6s - loss: 10.43 - ETA: 5s - loss: 10.43 - ETA: 4s - loss: 10.43 - ETA: 3s - loss: 10.42 - ETA: 2s - loss: 10.42 - ETA: 1s - loss: 10.42 - ETA: 1s - loss: 10.41 - ETA: 0s - loss: 10.41 - 15s 17ms/step - loss: 10.4184 - val_loss: 41177.9926\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 10.467 - ETA: 11s - loss: 10.436 - ETA: 10s - loss: 10.412 - ETA: 9s - loss: 10.410 - ETA: 8s - loss: 10.41 - ETA: 7s - loss: 10.40 - ETA: 6s - loss: 10.40 - ETA: 5s - loss: 10.39 - ETA: 4s - loss: 10.39 - ETA: 3s - loss: 10.39 - ETA: 2s - loss: 10.39 - ETA: 1s - loss: 10.39 - ETA: 1s - loss: 10.39 - ETA: 0s - loss: 10.39 - 15s 17ms/step - loss: 10.3967 - val_loss: 346802.0112\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - ETA: 12s - loss: 10.422 - ETA: 11s - loss: 10.400 - ETA: 10s - loss: 10.385 - ETA: 9s - loss: 10.397 - ETA: 8s - loss: 10.37 - ETA: 7s - loss: 10.37 - ETA: 6s - loss: 10.37 - ETA: 5s - loss: 10.37 - ETA: 4s - loss: 10.37 - ETA: 3s - loss: 10.37 - ETA: 2s - loss: 10.37 - ETA: 1s - loss: 10.38 - ETA: 1s - loss: 10.37 - ETA: 0s - loss: 10.37 - 15s 17ms/step - loss: 10.3778 - val_loss: 67174.4504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6227206d8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.fit([X, *y_true], np.zeros(len(X)), batch_size=64, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('yolo_train.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "input_x = [K.placeholder(shape=(None, 13*(2**i), 13*(2**i), 21)) for i in range(3)]\n",
    "input_y = [K.placeholder(shape=(None, 13*(2**i), 13*(2**i), 3, 7)) for i in range(3)]\n",
    "loss_tensor = yolo_loss([*input_x, *input_y], anchors, num_classes)\n",
    "loss = sess.run(loss_tensor, feed_dict={input_x[0]: y_pred[0], input_x[1]: y_pred[1], input_x[2]: y_pred[2],\n",
    "                                        input_y[0]: y_true[0][0:2], input_y[1]: y_true[1][0:2], input_y[2]: y_true[2][0:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
